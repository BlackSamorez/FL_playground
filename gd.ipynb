{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from typing import Collection, Tuple, Mapping\n",
    "from queue import SimpleQueue\n",
    "from copy import deepcopy\n",
    "\n",
    "class BasicCompressor:\n",
    "    def __init__(self, shapes: Mapping[str, torch.Size]):\n",
    "        self.shapes = shapes\n",
    "    \n",
    "    def compress(self, grad_dict: Mapping[str, Tensor]) -> Collection[Tensor]:\n",
    "        return (torch.cat(tuple(grad_dict[name].flatten() for name in sorted(grad_dict))),)\n",
    "                    \n",
    "    def decompress(self, data: Collection[Tensor]) -> Mapping[str, Tensor]:\n",
    "        x = data[0]\n",
    "        grad_dict = {}\n",
    "        for name in sorted(self.shapes):\n",
    "            shape = self.shapes[name]\n",
    "            grad_dict[name] = x[:shape.numel()].view(*shape)\n",
    "            x = x[shape.numel():]\n",
    "        return grad_dict\n",
    "    \n",
    "    \n",
    "def get_compressor(model: nn.Module) -> BasicCompressor:\n",
    "    return BasicCompressor(shapes={k: v.shape for k, v in model.named_parameters()})\n",
    "    \n",
    "def get_num_bits(dtype: torch.dtype) -> int:\n",
    "    if dtype.is_floating_point:\n",
    "        return torch.finfo(dtype).bits\n",
    "    else:\n",
    "        return torch.iinfo(dtype).bits\n",
    "\n",
    "class DataSender:\n",
    "    def __init__(self, queue: SimpleQueue) -> None:\n",
    "        self.queue = queue\n",
    "        self.n_bits_passed = 0\n",
    "        \n",
    "    def send(self, data: Collection[Tensor]):\n",
    "        for tensor in data:\n",
    "            self.n_bits_passed += get_num_bits(tensor.dtype) * tensor.numel()\n",
    "            \n",
    "        self.queue.put(data)\n",
    "        \n",
    "\n",
    "class DataReceiver:\n",
    "    def __init__(self, queue: SimpleQueue) -> None:\n",
    "        self.queue = queue\n",
    "        \n",
    "    def recv(self) -> Collection[Tensor]:\n",
    "        return self.queue.get()\n",
    "    \n",
    "def get_sender_receiver() -> Tuple[DataSender, DataReceiver]:\n",
    "    queue = SimpleQueue()\n",
    "    return DataSender(queue=queue), DataReceiver(queue=queue)\n",
    "        \n",
    "        \n",
    "\n",
    "def get_grad_dict(module: nn.Module) -> Mapping[str, Tensor]:\n",
    "    return {k:v.grad.detach() for k,v in module.named_parameters()}\n",
    "\n",
    "def add_grad_dict(module: nn.Module, grad_dict: Mapping[str, Tensor]):\n",
    "    for k,v in module.named_parameters():\n",
    "        v.grad = grad_dict[k]\n",
    "\n",
    "class Client:\n",
    "    def __init__(self, lr: float, data: Tuple[Tensor, Tensor], model: nn.Module, loss_fn, data_sender: DataSender, data_receiver: DataReceiver, compressor: BasicCompressor):\n",
    "        self.data = data\n",
    "        self.model = model\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.data_sender = data_sender\n",
    "        self.data_receiver = data_receiver\n",
    "        self.compressor = compressor\n",
    "        \n",
    "    def send_grad_get_loss(self):\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        loss = self.loss_fn(self.model(self.data[0]), self.data[1])\n",
    "        loss.backward()\n",
    "            \n",
    "        grad_dict = get_grad_dict(self.model)\n",
    "        msg = self.compressor.compress(grad_dict=grad_dict)\n",
    "        self.data_sender.send(msg)\n",
    "        return float(loss)\n",
    "        \n",
    "        \n",
    "    def apply_global_step(self):\n",
    "        msg = self.data_receiver.recv()\n",
    "        grad_dict = self.compressor.decompress(msg)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        add_grad_dict(self.model, grad_dict=grad_dict)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        \n",
    "class Master:\n",
    "    def __init__(self, lr: float, eval_data: Tuple[Tensor, Tensor],  model: nn.Module, data_senders: Collection[DataSender], data_receivers: Collection[DataReceiver], compressors: Collection[BasicCompressor], loss_fn):\n",
    "        self.eval_data = eval_data\n",
    "        self.model = model\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
    "        \n",
    "        self.data_senders = data_senders\n",
    "        self.data_receivers = data_receivers\n",
    "        self.compressors = compressors\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "    def scale_grads(self, scale: float):\n",
    "        for v in self.model.parameters():\n",
    "            v.grad *= scale\n",
    "    \n",
    "    def round(self) -> float:\n",
    "        self.model.zero_grad()\n",
    "        for receiver, compressor in zip(self.data_receivers, self.compressors):\n",
    "            msg = receiver.recv()\n",
    "            grad_dict = compressor.decompress(msg)\n",
    "            add_grad_dict(self.model, grad_dict=grad_dict)    \n",
    "        self.scale_grads(1 / len(self.data_senders))\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        for sender, compressor in zip(self.data_senders, self.compressors):\n",
    "            grad_dict = get_grad_dict(self.model)\n",
    "            msg = compressor.compress(grad_dict=grad_dict)\n",
    "            sender.send(msg)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            return float(self.loss_fn(self.model(self.eval_data[0]), self.eval_data[1]))\n",
    "            \n",
    "            \n",
    "def get_master_and_clients(lr: float, clients_data: Collection[Collection[Tuple[Tensor, Tensor]]], eval_data: Collection[Tuple[Tensor, Tensor]], model: nn.Module, loss_fn) -> Tuple[Master, Collection[Client]]:\n",
    "    num_clients = len(clients_data)\n",
    "    \n",
    "    uplink_comms = [get_sender_receiver() for _ in range(num_clients)]\n",
    "    downlink_comms = [get_sender_receiver() for _ in range(num_clients)]\n",
    "    compressors = [get_compressor(model=model) for _ in range(num_clients)]\n",
    "    client_models = [deepcopy(model) for _ in range(num_clients)]\n",
    "    \n",
    "    master = Master(\n",
    "        lr=lr,\n",
    "        eval_data=eval_data,\n",
    "        model=model,\n",
    "        data_senders=[s for s, r in downlink_comms],\n",
    "        data_receivers=[r for s, r in uplink_comms],\n",
    "        compressors=compressors,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "    \n",
    "    clients = []\n",
    "    for i in range(num_clients):\n",
    "        client = Client(\n",
    "            lr=lr,\n",
    "            data=clients_data[i],\n",
    "            model=client_models[i],\n",
    "            loss_fn=loss_fn,\n",
    "            data_sender=uplink_comms[i][0],\n",
    "            data_receiver=downlink_comms[i][1],\n",
    "            compressor=compressors[i],\n",
    "        )\n",
    "        clients.append(client)\n",
    "    \n",
    "    return master, clients\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_client(i:int, client: Client):\n",
    "    for _ in range(10):\n",
    "        loss = client.send_grad_get_loss()\n",
    "        # print(f\"Client {i}: {loss}\")\n",
    "        client.apply_global_step()\n",
    "        \n",
    "def run_master(master: Master):\n",
    "    for i in range(10):\n",
    "        print(f\"Master: {master.round()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "NUM_CLIENTS = 20\n",
    "\n",
    "data, labels = load_svmlight_file(\"phishing.txt\")\n",
    "enc_labels = labels.copy()\n",
    "data_dense = data.todense()\n",
    "\n",
    "eval_data = (torch.from_numpy(data_dense).to(torch.float32), torch.from_numpy(enc_labels).to(torch.float32)[:, None])\n",
    "clients_data = [(x, y) for x, y in zip(torch.split(eval_data[0], len(eval_data[0]) // NUM_CLIENTS, dim=0), torch.split(eval_data[1], len(eval_data[1]) // NUM_CLIENTS, dim=0))]\n",
    "\n",
    "model = torch.nn.Linear(eval_data[0].shape[1], 1, bias=False)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "master, clients = get_master_and_clients(\n",
    "    lr=200,\n",
    "    clients_data=clients_data,\n",
    "    eval_data=eval_data,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master: 0.6558125615119934\n",
      "Master: 0.611517608165741\n",
      "Master: 0.5869171619415283\n",
      "Master: 0.5614525675773621\n",
      "Master: 0.5421739816665649\n",
      "Master: 0.5248126983642578\n",
      "Master: 0.5100699663162231\n",
      "Master: 0.49705731868743896\n",
      "Master: 0.4855799674987793\n",
      "Master: 0.4753459393978119\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "client_threads = []\n",
    "for i, client in enumerate(clients):\n",
    "    client_threads.append(threading.Thread(target=run_client, args=(i, client)))\n",
    "    client_threads[-1].start()\n",
    "    \n",
    "master_thread = threading.Thread(target=run_master, args=(master,))\n",
    "master_thread.start()\n",
    "\n",
    "master_thread.join()\n",
    "for t in client_threads:\n",
    "    t.join()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
